# 3\. Lecture on Reinforcement Learning Framework

## Introduction

All right guys, so welcome to this uh lecture video and uh here we're going. to talk about a reinforcement learning framework.

## Overview of Reinforcement Learning

Previously we talked about the components of reinforcement learning and how they are linked together. We're going to look now at what the framework for reinforcement learning is.

### Markov Property

We're going to start with the fact that reinforcement learning obeys a Markov property. Right? Reinforcement learning is a Markov decision process. What does it mean? What do we mean by that?

#### Markov Decision Process

The Markov property and of reinforcement learning has features of a Markov decision process. A Markov decision process simply means that we make a decision based on our current state, right? And not based on any past or future information.

#### Example: Day Trading

So for example, the example of day trading: if I want to buy a stock today, I'll make a decision based on the information that I have about that stock today. So that's what the decision process states.

### Agent’s Role

We know that our agent is the one taking decisions; it's taking action. So those decisions are just the actions the agent is taking. For it to obey the Markov property, the observation that we give it is going to be the observation of one state.

#### Time-Based Decision Making

If we are making a decision at time T equals to 2, we are only going to give the information about T equals to 2. Right? So it's going to see the price 22k and if we're making a decision at time T equals to 3, it's going to see the price 21k being sent to the agent. So at any point in time, the agent only receives information about its current state.

## Reinforcement Learning Loop

Moving further, let's look at what the reinforcement learning loop is. It's a sequential decision-making process.

### Sequence of Decisions

We know our reinforcement learning is a sequential decision-making process. So how does that sequence look like?

#### The Loop Sequence

We make a decision every time we get an observation, we make a decision, we get a reward, and we go to the next observation. So that's the sequential loop of reinforcement learning.

### Daily Trading Example

You can think of this like if you have 30 days of trading: on the first day of the month, you see the price, and then you take an action, you buy or sell, you make a profit or you lose, and then you go to the next day.

#### Reinforcement Learning Sequence

So in the reinforcement learning sequence, you start at state S0. When you're given that state, you take an action A0. When you take that action, you get a reward for that action and then you move to the next state S1.

### Terminal State

This process continues until we reach the terminal state or the last state. For example, if you're trading on a monthly basis, your terminal state is the last day of the month.

## Reinforcement Learning Outputs

To summarize the reinforcement learning loop, we can say that the output consists of state, action, rewards, and the next state.

### Agent's Interaction

So, in every looping sequence, you have a state. Based on that state, we take an action. Based on that action, we get a reward and then we move to the next state.

### Repeated Process

This process repeats itself until the last day of trading. If you’re trading for a month, this agent will perform this loop for a month and then calculate the total reward, which is the goal of the agent: to maximize its cumulative reward.

## Central Idea: Reward Hypothesis

There’s a central idea in reinforcement learning called the reward hypothesis. This reward defines the behavior of the agent.

### Goal of the Agent

The goal of the agent is to maximize its expected return. In the case of day trading, maybe you set your period for a month to maximize the total profit it makes in that month.

## Putting It All Together

To emphasize the components of the framework, we have an environment.

### Environment and State

![](Files/image%202.png)

This environment can be represented as a timeline where it produces a state at various points. Based on that state, the agent takes an action and receives a reward.

#### Flow of Action

So when the agent takes an action, it will move to a new state and receive a reward based on that action leading to the new state.

## Conclusion

This is the reinforcement learning framework. In every step, we get one state, the agent takes an action, and gets a reward. So a decision is based on one state.

Thank you guys for watching and see you in the next video.